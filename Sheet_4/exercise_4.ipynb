{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/simplewiki-2020-11-01.jsonl.gz\"\n",
    "if not os.path.exists(filepath):\n",
    "    util.http_get(\"http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz\", filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 169597 articles, 509663 paragraphs, and 2025547 sentences.\n",
      "Sample article: {'id': '9822', 'title': 'Ted Cassidy'}\n",
      "Sample paragraph: {'article_id': '9822', 'id': '9822:0', 'text': 'Ted Cassidy (July 31, 1932 - January 16, 1979) was an American actor. He was best known for his roles as Lurch and Thing on \"The Addams Family\".'}\n",
      "Sample sentence: {'paragraph_id': '9822:0', 'id': '9822:0:0', 'text': 'Ted Cassidy (July 31, 1932 - January 16, 1979) was an American actor'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize containers for collection\n",
    "articles = []\n",
    "paragraphs = []\n",
    "sentences = []\n",
    "\n",
    "# Read and process the dataset\n",
    "with gzip.open(filepath, \"rt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        article_id = data[\"id\"]\n",
    "        article_title = data[\"title\"]\n",
    "\n",
    "        # Store article-level information\n",
    "        articles.append({\"id\": article_id, \"title\": article_title})\n",
    "\n",
    "        for i, paragraph_text in enumerate(data[\"paragraphs\"]):\n",
    "            paragraph_id = f\"{article_id}:{i}\"\n",
    "\n",
    "            # Store paragraph-level information\n",
    "            paragraphs.append(\n",
    "                {\"article_id\": article_id, \"id\": paragraph_id, \"text\": paragraph_text}\n",
    "            )\n",
    "\n",
    "            # Split paragraph into sentences\n",
    "            paragraph_sentences = paragraph_text.split(\".\")\n",
    "\n",
    "            for j, sentence_text in enumerate(paragraph_sentences):\n",
    "                sentence_id = f\"{paragraph_id}:{j}\"\n",
    "\n",
    "                # Store sentence-level information\n",
    "                sentences.append(\n",
    "                    {\n",
    "                        \"paragraph_id\": paragraph_id,\n",
    "                        \"id\": sentence_id,\n",
    "                        \"text\": sentence_text.strip(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "# Output sample data for verification\n",
    "print(\n",
    "    f\"Loaded {len(articles)} articles, {len(paragraphs)} paragraphs, and {len(sentences)} sentences.\"\n",
    ")\n",
    "print(\"Sample article:\", articles[0] if articles else \"No articles found.\")\n",
    "print(\"Sample paragraph:\", paragraphs[0] if paragraphs else \"No paragraphs found.\")\n",
    "print(\"Sample sentence:\", sentences[0] if sentences else \"No sentences found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63299/63299 [19:17<00:00, 54.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 2025547 sentences with embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load the sentence transformer model\n",
    "model_name = \"all-MiniLM-L6-v2\"  # Choose 'all-mpnet-base-v2' for best quality\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Encode sentences\n",
    "sentence_texts = [s[\"text\"] for s in sentences]\n",
    "sentence_embeddings = model.encode(\n",
    "    sentence_texts, convert_to_numpy=True, show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Check embedding dimensions\n",
    "embedding_dim = sentence_embeddings.shape[1]\n",
    "print(\n",
    "    f\"Encoded {len(sentence_embeddings)} sentences with embedding dimension: {embedding_dim}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic search example\n",
    "def find_similar_sentences(query, top_k=5):\n",
    "    query_embedding = model.encode(query, convert_to_numpy=True)\n",
    "    hits = util.semantic_search(query_embedding, sentence_embeddings, top_k=top_k)\n",
    "    results = [\n",
    "        {\n",
    "            \"sentence\": sentence_texts[hit[\"corpus_id\"]],\n",
    "            \"paragraph_id\": sentences[hit[\"corpus_id\"]][\"paragraph_id\"],\n",
    "            \"score\": hit[\"score\"],\n",
    "        }\n",
    "        for hit in hits[0]\n",
    "    ]\n",
    "    return results\n",
    "\n",
    "\n",
    "# Generate prompt\n",
    "def generate_prompt(query, context):\n",
    "    instruction = \"You are a question answering bot. Use the context below to answer the user's question.\"\n",
    "    prompt = f\"{instruction}\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{query}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand context to include neighboring paragraphs\n",
    "def expand_context(paragraph_id):\n",
    "    context = []\n",
    "    article_id, paragraph_idx = paragraph_id.split(\":\")\n",
    "    paragraph_idx = int(paragraph_idx)\n",
    "\n",
    "    for offset in [-1, 0, 1]:\n",
    "        neighbor_idx = paragraph_idx + offset\n",
    "        neighbor_id = f\"{article_id}:{neighbor_idx}\"\n",
    "        neighbor_paragraph = next(\n",
    "            (p[\"text\"] for p in paragraphs if p[\"id\"] == neighbor_id), None\n",
    "        )\n",
    "        if neighbor_paragraph:\n",
    "            context.append(neighbor_paragraph)\n",
    "\n",
    "    return \"\\n\\n\".join(context)\n",
    "\n",
    "\n",
    "# Combine similar paragraphs and expand context\n",
    "def construct_context(similar_sentences):\n",
    "    paragraph_ids = set()\n",
    "    context = []\n",
    "    for result in similar_sentences:\n",
    "        if result[\"paragraph_id\"] not in paragraph_ids:\n",
    "            paragraph_ids.add(result[\"paragraph_id\"])\n",
    "            expanded_context = expand_context(result[\"paragraph_id\"])\n",
    "            context.append(expanded_context)\n",
    "    return \"\\n\\n\".join(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated prompt:\n",
      "You are a question answering bot. Use the context below to answer the user's question.\n",
      "\n",
      "Context:\n",
      "Île-de-France is a region of France. The capital city is Paris. It is also the capital city of France. In 2013 about 12 million people lived in the region. About 2.1 million people live in the city of Paris.\n",
      "\n",
      "There are 8 departments in the region. They are:\n",
      "\n",
      "The capital of France is Paris. In the course of history, the national capital has been in many locations other than Paris.\n",
      "\n",
      "During the Protestant Reformation, a huge massacre of French Protestants started there in 1572, called the Saint Bartholomew Day Massacre. Paris saw many other troubles over the years of the \"\"Ancien Régime\"\" (Old Kingdom), then in 1789, the French Revolution began in Paris, leading to more massacres.\n",
      "\n",
      "Paris was the Capital of the French Empire which, as well as France, covered Spain, Belgium, Holland, Luxembourg, Switzerland, Italy, most of Germany and some of Austria, Croatia, Slovenia and Poland. The Empire ruled by Napoleon was from 1804-1814/1815. The Russian army seized Paris from Napoleon in 1814, and the Prussian army captured it in 1871. The next time it was captured was by the Nazi Germans in 1940. The Allies freed the city in 1944 and it has not since been captured.\n",
      "\n",
      "Paris has an oceanic climate in the Köppen climate classification. It has warm summers and cold winters, and rainfall year-round.\n",
      "\n",
      "Veyrier is a municipality of the Canton of Geneva, Switzerland. It borders France. About 11,000 people were living in Veyrier in 2015.\n",
      "\n",
      "The municipality includes the localities of Pinchat, Vessy and Sierne.\n",
      "\n",
      "Question:\n",
      "What is the capital of France?\n",
      "Saved sentence embeddings to data/sentence_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"What is the capital of France?\"\n",
    "similar_sentences = find_similar_sentences(query)\n",
    "context = construct_context(similar_sentences)\n",
    "prompt = generate_prompt(query, context)\n",
    "\n",
    "print(\"Generated prompt:\")\n",
    "print(prompt)\n",
    "\n",
    "# Optionally, save embeddings and related data for later use\n",
    "np.save(\"data/sentence_embeddings.npy\", sentence_embeddings)\n",
    "print(\"Saved sentence embeddings to data/sentence_embeddings.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
